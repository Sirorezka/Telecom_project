data[is.na(data$device_type),"device_type"] = -1
data[is.na(data$device_platform),"device_platform"] = -1
data[is.na(data$device_vendor),"device_vendor"] = -1
# converting long, lat, start_angle, end_angle to numeric
data$long <- as.numeric.factor(data$long)
data$lat <- as.numeric.factor(data$lat)
data$start_angle <- as.numeric.factor(data$start_angle)
data$end_angle <- as.numeric.factor(data$end_angle)
# we need to check if cid is unique and can be used as key for base station:
tb_cid_check <- unique(data[,c('lac','cid')])
tb_cid_check <- tb_cid_check %>% group_by(cid) %>% summarize (mm=length(list(lac)))
if (max(tb_cid_check$mm) == 1) print ("All cids are unique")
####
####  --- Plotting paths ---
####
# plot all paths on one graph with imei codes. We are searching for data with matching imei codes
if (MAKE_PLOTS) plot_all_fact_data (data_fact, data)
####
####  --- Generating train set ---
####
# Generating all posible combinations of msidns
all_fact_ids <- c(data_fact[,1],data_fact[,2])
sort(all_fact_ids)
y_train <- generate_all_combin (all_fact_ids)
# 'class' column will contain information if two msidn's match
y_train[,"class"] <- 0
# two msidn's match if they are present in fact_data
aa <- paste0(y_train[,"V1"],"_",y_train[,"V2"], collapse = NULL)
bb <- paste0(data_fact[,1],"_",data_fact[,2], collapse = NULL)
class1 <- aa %in% bb
y_train[class1,"class"] <- 1
# Sampling training data:
#
# - We need to take all pairs from class 1.
# - And for clazz 0 we will sample some points that not present in original data
y_train_1 <- y_train[y_train$class==1,]
y_train_0 <- y_train[y_train$class==0,]
y_train_0 <- y_train_0[sample(nrow(y_train_0),1100),]
y_train <- bind_rows(y_train_1,y_train_0)
rm(y_train_0,y_train_1)
if (MAKE_PLOTS) plot_all_y_train (y_train, data)
###
###  ---  Generating factors  ---
###
all_factors <- y_train[,c('V1','V2')]
# joining cids to train table
tt <- data[,c('msisdn','cid')] %>% group_by(msisdn) %>% summarise(cids = list(unique(cid)))
all_factors <- all_factors %>% left_join (tt, by = c('V1' = 'msisdn'), copy= T)
all_factors <- all_factors %>% left_join (tt, by = c('V2' = 'msisdn'), copy= T)
names(all_factors)[3:4] <- c('cids_V1','cids_V2')
# computing SymmetricSimilarity
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(ss =length(intersect(cids_V1[[1]],cids_V2[[1]]))/ length(unique(cids_V1[[1]],cids_V2[[1]])))
# computing S2
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s2 =length(intersect(cids_V1[[1]],cids_V2[[1]]))/ min(length(cids_V1[[1]]),length(cids_V2[[1]])))
# computing S3
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s3 =length(intersect(cids_V1[[1]],cids_V2[[1]]))/ ( ( length(cids_V1[[1]]) +length(cids_V2[[1]]))/2 ))
# phones full name match and phone type match for pairs of msisdn's
phones <- unique(data[,c('msisdn','device_vendor','device_platform','device_type')])
phones$device_type [phones$device_type =="Phone"] = "SmartPhone"
phones <- phones %>% mutate(phone_full = paste0(device_vendor,"_",device_platform,"_",device_type))
phones <- phones[phones$device_type!=-1,]
phone_type <- unique(phones[,c('msisdn','device_type')])
phone_type$unit <- 1
phone_type <- phone_type %>% group_by(msisdn) %>% spread(key=device_type, value = unit, fill = 0)
devices <- t(summarise_each (phone_type[,2:6],funs(sum)))
devices <- as.data.frame(devices)
if (MAKE_PLOTS)  {
# ploting devices by number of occurences in data
dev_plot <- ggplot(data=devices, aes(x=rownames(devices), y=V1))
dev_plot <- dev_plot + geom_bar(stat="summary", fun.y=sum, aes(fill =rownames(devices)))
dev_plot
}
phones <- phones[,c('msisdn','phone_full')]
phones <- phones %>% group_by(msisdn) %>% summarise(phone_lst = list(phone_full))
phones <- phones %>% left_join (phone_type, by = c('msisdn'))
all_factors <- all_factors %>% left_join (phones, by = c('V1' = 'msisdn'), copy= T, fill = 0)
all_factors <- all_factors %>% left_join (phones, by = c('V2' = 'msisdn'), copy= T, fill = 0)
names(all_factors)
col_del <- c(NULL)
for (i in rownames(devices)){
all_factors[is.na(all_factors[,paste0(i,".y")]),paste0(i,".y")] <-0
all_factors[is.na(all_factors[,paste0(i,".x")]),paste0(i,".x")] <-0
all_factors[,i] <- all_factors[,paste0(i,".x")] + all_factors[,paste0(i,".y")]
col_del <- c(col_del,paste0(i,".x"),paste0(i,".y"))
}
all_factors <- all_factors [,!(names(all_factors) %in% col_del)]
# full phone name match
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(phone_matched =min(length(unlist(phone_lst.x)),length(unlist(phone_lst.y)),length(intersect(phone_lst.x,phone_lst.y))))
# phones vendor match
phone_vendor <- unique(data[,c('msisdn','device_vendor')])
phone_vendor <- phone_vendor[phone_vendor$device_vendor!=-1,]
phone_vendor <- phone_vendor %>% group_by(msisdn) %>% summarise(vend_lst = list(device_vendor))
all_factors <- all_factors %>% left_join (phone_vendor, by = c('V1' = 'msisdn'), copy= T, fill = 0)
all_factors <- all_factors %>% left_join (phone_vendor, by = c('V2' = 'msisdn'), copy= T, fill = 0)
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(vendor_matched =min(length(unlist(vend_lst.x)),length(unlist(vend_lst.y)),length(intersect(vend_lst.x,vend_lst.y))))
all_factors <- all_factors [,!(names(all_factors) %in% c('vend_lst.x','vend_lst.y'))]
# ploting station usage - number of unique msisdn's registered in each cid
if (MAKE_PLOTS)  plot_cids_distrib(data,img_path = "ppt_plots")
##  Computing L1 and L2 distances between points
##
mm <- detectCores()
cl <- makeCluster (mm)
registerDoParallel (cl)
tb_res_dist <- foreach (i = 1:nrow(y_train), .combine =rbind, .packages =c('geosphere') ) %dopar%{
print (i)
#i <- 910
v1 <- y_train[i,1][[1]]
v2 <- y_train[i,2][[1]]
path1 <- data [data$msisdn==v1,c('tstamp','long','lat')]
path2 <- data [data$msisdn==v2,c('tstamp','long','lat')]
tt <- cbind(path1[1:(nrow(path1)-1),],path1[2:nrow(path1),])
tt$sq <- distCosine (tt[,2:3],tt[,5:6])
l2_dist1 <- sqrt(sum(tt$sq[tt$sq!=0]^2)/nrow(tt))
l1_dist1 <- sum(abs(tt$sq[tt$sq!=0]))/nrow(tt)
path1 <- rbind(path1,path2)
path1 <- path1[order(path1$tstamp),]
tt <- cbind(path1[1:(nrow(path1)-1),],path1[2:nrow(path1),])
tt$sq <- distCosine (tt[,2:3],tt[,5:6])
l2_dist2 <- sqrt(sum(tt$sq[tt$sq!=0]^2)/nrow(tt))
l1_dist2 <- sum(abs(tt$sq[tt$sq!=0]))/nrow(tt)
tb_dist <- c(i, l2_dist1,l2_dist2,l1_dist1,l1_dist2)
tb_dist
}
stopCluster(cl)
tb_res_dist <- as.data.frame(tb_res_dist)
tb_res_dist <- tb_res_dist[order(tb_res_dist$V1),]
all_factors[,'l2_dist_diff_1'] <- (tb_res_dist$V3 - tb_res_dist$V2)
all_factors[,'l1_dist_diff_1'] <- (tb_res_dist$V5 - tb_res_dist$V4)
all_factors[,'l2_dist_diff_2'] <- abs(tb_res_dist$V3 - tb_res_dist$V2)
all_factors[,'l1_dist_diff_2'] <- abs(tb_res_dist$V5 - tb_res_dist$V4)
rm(tb_res_dist)
CONST_SHORT_PATH_VAL <- 3
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
## unique points
tb_path_length <-data_adj %>% group_by (msisdn) %>% summarize(lac_unique = list(paste0(long,"_",lat)))
tb_path_length <- tb_path_length %>% group_by (msisdn) %>% summarize (lac_unique = list(unique(lac_unique[[1]])))
tb_path_length <- tb_path_length %>% group_by (msisdn) %>% summarize (lac_unique = length(lac_unique[[1]]))
all_train_ids <- all_train_ids %>% left_join(tb_path_length, by = c('msisdn' = 'msisdn'))
short_pathes <- all_train_ids[all_train_ids$lac_unique <= CONST_SHORT_PATH_VAL,]
satation_list <- unique(data[,c('lac','cid','long','lat','max_dist','start_angle','end_angle')])
mm <- detectCores()
cl <- makeCluster (mm)
registerDoParallel (cl)
tb_data_adj_new <- foreach (i = 1:nrow(short_pathes), .combine =rbind, .packages=c('geosphere','dplyr','tidyr')) %dopar%{
#for (i in 1:nrow(short_pathes)){
## interate over all 'msidns' that have less than three stations
#print (paste0("i: ", i))
curr_msid <- short_pathes[i,1]
cur_stations <- data_adj[data_adj$msisdn == curr_msid,]
lac_intersect_full <- data.frame(NULL)
for (j in 1:nrow(cur_stations)){
## for each visited stations check all nearest stations - stations of possible visit
#print (paste0("j: ",j))
lac_intersect <- data.frame(NULL)
cur_station <- cur_stations[j,c('lac','cid','long','lat','max_dist','start_angle','end_angle')]
temp_st_list <- satation_list[,]
# removing stations that are too far from current
temp_st_list$V1 <- cur_station$long
temp_st_list$V2 <- cur_station$lat
temp_st_list$dist <- sqrt((temp_st_list$long-temp_st_list$V1)**2 + (temp_st_list$lat-temp_st_list$V2)**2)
# estimated filter for distance, '1' - is the unit dist in lat/long coordinates
# 111000 is the apx. number of meters in a unit of dist in lat/long coordinates
# 1000 - aprx. average max.distance for all stations
# cur_station$max_dist was added to the formula, because some stations have max.dist equal to 15 km.
#filt <- 0.1
#filt <- 1 / 111000 * max (1000 *2, cur_station$max_dist+1000)
filt <- 1 / 111000 * (cur_station$max_dist+1000)
temp_st_list <- temp_st_list[temp_st_list$dist < filt,]
temp_st_list <- temp_st_list[temp_st_list$dist > 1e-5,]
if (nrow(temp_st_list)>0) {
for (k in 1:nrow(temp_st_list)){
# print(k)
point1 <- cur_station
point2 <- temp_st_list[k,]
p1_all_coord <- get_triangle_area (point1)
p2_all_coord <- get_triangle_area (point2)
# looking for points of intersection between two stations
p_inter1 <- get_all_edges_intersect (p1_all_coord, p2_all_coord)
# print(p_inter1)
# tt <- plot_triangle (point1,point2)
# tt
p_inter2 <- get_all_inner_intersec (point1,point2, p1_all_coord, p2_all_coord)
# print (p_inter2)
p_inter <- unique(bind_rows (p_inter1, p_inter2))
df <- as.data.frame(c(point2,k))
colnames(df)[11] <- "k_val"
if (nrow(p_inter)>0)  lac_intersect <- bind_rows(lac_intersect,df)
}
}
# we need to add all necessary columns to lac_intersect data to bind rows in data_adj later
if (nrow(lac_intersect)>0) {
cur_station <- cur_stations[j,]
new_cols <- !(names(cur_station) %in% names(lac_intersect))
new_clos <- names(cur_station)[new_cols]
for (t in new_clos){
lac_intersect[,t] = cur_stations[j,t]
}
# rearranging columns
lac_intersect <- lac_intersect [,names(cur_station)]
lac_intersect_full <- bind_rows(lac_intersect_full, lac_intersect)
}
}
lac_intersect_full
}
stopCluster(cl)
nrow(tb_data_adj_new)
tb_path_length
data_adj
CONST_SHORT_PATH_VAL <- 3
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
new_base_stat <- get_all_nearest_stations (data_adj,all_train_ids,CONST_SHORT_PATH_VAL)
###
###  --- Function computes nearest base station to the selected ids
###
###   data_adj - should have same structure as original data table
###   all_train_ids - ids that we want to process
###   SHOR_PATH_VAL - filter for ids. Only ids with number of base stations equal or less than constant will be processed
###
get_all_nearest_stations <- function (data_adj, all_train_ids, SHOR_PATH_VAL){
## unique points
tb_path_length <-data_adj %>% group_by (msisdn) %>% summarize(lac_unique = list(paste0(long,"_",lat)))
tb_path_length <- tb_path_length %>% group_by (msisdn) %>% summarize (lac_unique = list(unique(lac_unique[[1]])))
tb_path_length <- tb_path_length %>% group_by (msisdn) %>% summarize (lac_unique = length(lac_unique[[1]]))
all_train_ids <- all_train_ids %>% left_join(tb_path_length, by = c('msisdn' = 'msisdn'))
short_pathes <- all_train_ids[all_train_ids$lac_unique <= SHOR_PATH_VAL,]
satation_list <- unique(data[,c('lac','cid','long','lat','max_dist','start_angle','end_angle')])
ptm <- proc.time()
mm <- detectCores()
cl <- makeCluster (mm)
registerDoParallel (cl)
tb_data_adj_new <- foreach (i = 1:nrow(short_pathes), .combine =rbind, .packages=c('geosphere','dplyr','tidyr')) %dopar%{
#for (i in 1:nrow(short_pathes)){
## interate over all 'msidns' that have less than three stations
#print (paste0("i: ", i))
curr_msid <- short_pathes[i,1]
cur_stations <- data_adj[data_adj$msisdn == curr_msid,]
lac_intersect_full <- data.frame(NULL)
for (j in 1:nrow(cur_stations)){
## for each visited stations check all nearest stations - stations of possible visit
#print (paste0("j: ",j))
lac_intersect <- data.frame(NULL)
cur_station <- cur_stations[j,c('lac','cid','long','lat','max_dist','start_angle','end_angle')]
temp_st_list <- satation_list[,]
# removing stations that are too far from current
temp_st_list$V1 <- cur_station$long
temp_st_list$V2 <- cur_station$lat
temp_st_list$dist <- sqrt((temp_st_list$long-temp_st_list$V1)**2 + (temp_st_list$lat-temp_st_list$V2)**2)
# estimated filter for distance, '1' - is the unit dist in lat/long coordinates
# 111000 is the apx. number of meters in a unit of dist in lat/long coordinates
# 1000 - aprx. average max.distance for all stations
# cur_station$max_dist was added to the formula, because some stations have max.dist equal to 15 km.
#filt <- 0.1
#filt <- 1 / 111000 * max (1000 *2, cur_station$max_dist+1000)
filt <- 1 / 111000 * (cur_station$max_dist+1000)
temp_st_list <- temp_st_list[temp_st_list$dist < filt,]
temp_st_list <- temp_st_list[temp_st_list$dist > 1e-5,]
if (nrow(temp_st_list)>0) {
for (k in 1:nrow(temp_st_list)){
# print(k)
point1 <- cur_station
point2 <- temp_st_list[k,]
p1_all_coord <- get_triangle_area (point1)
p2_all_coord <- get_triangle_area (point2)
# looking for points of intersection between two stations
p_inter1 <- get_all_edges_intersect (p1_all_coord, p2_all_coord)
# print(p_inter1)
# tt <- plot_triangle (point1,point2)
# tt
p_inter2 <- get_all_inner_intersec (point1,point2, p1_all_coord, p2_all_coord)
# print (p_inter2)
p_inter <- unique(bind_rows (p_inter1, p_inter2))
df <- as.data.frame(c(point2,k))
colnames(df)[11] <- "k_val"
if (nrow(p_inter)>0)  lac_intersect <- bind_rows(lac_intersect,df)
}
}
# we need to add all necessary columns to lac_intersect data to bind rows in data_adj later
if (nrow(lac_intersect)>0) {
cur_station <- cur_stations[j,]
new_cols <- !(names(cur_station) %in% names(lac_intersect))
new_clos <- names(cur_station)[new_cols]
for (t in new_clos){
lac_intersect[,t] = cur_stations[j,t]
}
# rearranging columns
lac_intersect <- lac_intersect [,names(cur_station)]
lac_intersect_full <- bind_rows(lac_intersect_full, lac_intersect)
}
}
lac_intersect_full
}
stopCluster(cl)
print ("time of execution: ")
print (proc.time() - ptm)
tb_data_adj_new
}
CONST_SHORT_PATH_VAL <- 3
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
new_base_stat <- get_all_nearest_stations (data_adj,all_train_ids,CONST_SHORT_PATH_VAL)
CONST_SHORT_PATH_VAL <- 3
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
new_base_stat <- get_all_nearest_stations (data_adj,all_train_ids,CONST_SHORT_PATH_VAL)
source ('my_utils.R')
CONST_SHORT_PATH_VAL <- 3
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
new_base_stat <- get_all_nearest_stations (data_adj,all_train_ids,CONST_SHORT_PATH_VAL)
get_all_nearest_stations <- function (data_adj, all_train_ids, SHOR_PATH_VAL){
## unique points
tb_path_length <-data_adj %>% group_by (msisdn) %>% summarize(lac_unique = list(paste0(long,"_",lat)))
tb_path_length <- tb_path_length %>% group_by (msisdn) %>% summarize (lac_unique = list(unique(lac_unique[[1]])))
tb_path_length <- tb_path_length %>% group_by (msisdn) %>% summarize (lac_unique = length(lac_unique[[1]]))
all_train_ids <- all_train_ids %>% left_join(tb_path_length, by = c('msisdn' = 'msisdn'))
short_pathes <- all_train_ids[all_train_ids$lac_unique <= SHOR_PATH_VAL,]
satation_list <- unique(data[,c('lac','cid','long','lat','max_dist','start_angle','end_angle')])
ptm <- proc.time()
mm <- detectCores()
cl <- makeCluster (mm)
registerDoParallel (cl)
tb_data_adj_new <- foreach (i = 1:nrow(short_pathes), .combine =rbind, .packages=c('geosphere','dplyr','tidyr')) %dopar%{
source ('my_utils.R')
#for (i in 1:nrow(short_pathes)){
## interate over all 'msidns' that have less than three stations
#print (paste0("i: ", i))
curr_msid <- short_pathes[i,1]
cur_stations <- data_adj[data_adj$msisdn == curr_msid,]
lac_intersect_full <- data.frame(NULL)
for (j in 1:nrow(cur_stations)){
## for each visited stations check all nearest stations - stations of possible visit
#print (paste0("j: ",j))
lac_intersect <- data.frame(NULL)
cur_station <- cur_stations[j,c('lac','cid','long','lat','max_dist','start_angle','end_angle')]
temp_st_list <- satation_list[,]
# removing stations that are too far from current
temp_st_list$V1 <- cur_station$long
temp_st_list$V2 <- cur_station$lat
temp_st_list$dist <- sqrt((temp_st_list$long-temp_st_list$V1)**2 + (temp_st_list$lat-temp_st_list$V2)**2)
# estimated filter for distance, '1' - is the unit dist in lat/long coordinates
# 111000 is the apx. number of meters in a unit of dist in lat/long coordinates
# 1000 - aprx. average max.distance for all stations
# cur_station$max_dist was added to the formula, because some stations have max.dist equal to 15 km.
#filt <- 0.1
#filt <- 1 / 111000 * max (1000 *2, cur_station$max_dist+1000)
filt <- 1 / 111000 * (cur_station$max_dist+1000)
temp_st_list <- temp_st_list[temp_st_list$dist < filt,]
temp_st_list <- temp_st_list[temp_st_list$dist > 1e-5,]
if (nrow(temp_st_list)>0) {
for (k in 1:nrow(temp_st_list)){
# print(k)
point1 <- cur_station
point2 <- temp_st_list[k,]
p1_all_coord <- get_triangle_area (point1)
p2_all_coord <- get_triangle_area (point2)
# looking for points of intersection between two stations
p_inter1 <- get_all_edges_intersect (p1_all_coord, p2_all_coord)
# print(p_inter1)
# tt <- plot_triangle (point1,point2)
# tt
p_inter2 <- get_all_inner_intersec (point1,point2, p1_all_coord, p2_all_coord)
# print (p_inter2)
p_inter <- unique(bind_rows (p_inter1, p_inter2))
df <- as.data.frame(c(point2,k))
colnames(df)[11] <- "k_val"
if (nrow(p_inter)>0)  lac_intersect <- bind_rows(lac_intersect,df)
}
}
# we need to add all necessary columns to lac_intersect data to bind rows in data_adj later
if (nrow(lac_intersect)>0) {
cur_station <- cur_stations[j,]
new_cols <- !(names(cur_station) %in% names(lac_intersect))
new_clos <- names(cur_station)[new_cols]
for (t in new_clos){
lac_intersect[,t] = cur_stations[j,t]
}
# rearranging columns
lac_intersect <- lac_intersect [,names(cur_station)]
lac_intersect_full <- bind_rows(lac_intersect_full, lac_intersect)
}
}
lac_intersect_full
}
stopCluster(cl)
print ("time of execution: ")
print (proc.time() - ptm)
tb_data_adj_new
}
CONST_SHORT_PATH_VAL <- 3
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
new_base_stat <- get_all_nearest_stations (data_adj,all_train_ids,CONST_SHORT_PATH_VAL)
new_base_stat
nrow(new_base_stat)
nrow(data_adj)
data_adj <- bind_rows(data_adj, new_base_stat)
nrow(data_adj)
###
###  Calculating new SS, S2, S3 measures for data_adj
###
# tt will have all cids
tt <- data_adj[,c('msisdn','cid')] %>% group_by(msisdn) %>% summarise(cids_adj = list(unique(cid)))
all_factors <- all_factors %>% left_join (tt, by = c('V1' = 'msisdn'), copy= T)
all_factors <- all_factors %>% left_join (tt, by = c('V2' = 'msisdn'), copy= T)
colnames(all_factors)[(ncol(all_factors)-1):ncol(all_factors)] <- c('cids_adj_V1','cids_adj_V2')
# computing SymmetricSimilarity
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(ss_adj =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ length(unique(cids_adj_V1[[1]],cids_adj_V2[[1]])))
# computing S2
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s2_adj =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ min(length(cids_adj_V1[[1]]),length(cids_adj_V2[[1]])))
# computing S3
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s3_adj =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ ((length(cids_adj_V1[[1]]) +length(cids_adj_V2[[1]]))/2 ))
write.table(y_train, "pr_data/y_train.csv", sep=",")
fact_short <- all_factors [,!(colnames(all_factors) %in% c("cids_V1","cids_V2","phone_lst.x","phone_lst.y","cids_adj_V1","cids_adj_V2"))]
write.table(fact_short, "pr_data/factors.csv", sep=",")
y_pred <- read.csv2 ("pr_data/y_pred.csv", header= FALSE, quote = '"', colClasses= c('numeric'))
not_matched <- y_train[y_train[,'class'] != y_pred,]
not_matched$pred <- y_pred[y_train[,'class'] != y_pred]
plot_all_y_train (not_matched, data, img_path="non_matched")
plot_all_y_train (not_matched, data, img_path="non_matched")
CONST_SHORT_PATH_VAL <- 99
data_adj <- data    # we will add new rows to the copy of data
all_train_ids <- unique(c (y_train$V1,y_train$V2))
all_train_ids <- as.data.frame(all_train_ids)
names(all_train_ids) <- 'msisdn'
new_base_stat <- get_all_nearest_stations (data_adj,all_train_ids,CONST_SHORT_PATH_VAL)
print ("IMPORTANT STATS:")
nrow(new_base_stat)
nrow(data_adj)
data_adj <- bind_rows(data_adj, new_base_stat)
nrow(data_adj)
###
###  Calculating new SS, S2, S3 measures for data_adj
###
# tt will have all cids
tt <- data_adj[,c('msisdn','cid')] %>% group_by(msisdn) %>% summarise(cids_adj = list(unique(cid)))
all_factors <- all_factors %>% left_join (tt, by = c('V1' = 'msisdn'), copy= T)
all_factors <- all_factors %>% left_join (tt, by = c('V2' = 'msisdn'), copy= T)
colnames(all_factors)[(ncol(all_factors)-1):ncol(all_factors)] <- c('cids_adj_V1','cids_adj_V2')
# computing SymmetricSimilarity
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(ss_adj_v2 =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ length(unique(cids_adj_V1[[1]],cids_adj_V2[[1]])))
# computing S2
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s2_adj_v2 =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ min(length(cids_adj_V1[[1]]),length(cids_adj_V2[[1]])))
# computing S3
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s3_adj_v2 =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ ((length(cids_adj_V1[[1]]) +length(cids_adj_V2[[1]]))/2 ))
View(all_factors)
View(all_factors)
names(all_factors)
names(all_factors)[21:22]
names(all_factors)[21:22] <- c("cids_adj_V1_old", "cids_adj_V2_old")
# computing SymmetricSimilarity
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(ss_adj_v2 =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ length(unique(cids_adj_V1[[1]],cids_adj_V2[[1]])))
# computing S2
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s2_adj_v2 =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ min(length(cids_adj_V1[[1]]),length(cids_adj_V2[[1]])))
# computing S3
all_factors <- all_factors %>% group_by(V1,V2) %>%
mutate(s3_adj_v2 =length(intersect(cids_adj_V1[[1]],cids_adj_V2[[1]]))/ ((length(cids_adj_V1[[1]]) +length(cids_adj_V2[[1]]))/2 ))
write.table(y_train, "pr_data/y_train.csv", sep=",")
fact_short <- all_factors [,!(colnames(all_factors) %in% c("cids_V1","cids_V2","phone_lst.x","phone_lst.y","cids_adj_V1","cids_adj_V2"))]
write.table(fact_short, "pr_data/factors.csv", sep=",")
View(all_factors)
fact_short <- all_factors [,!(colnames(all_factors) %in% c("cids_V1","cids_V2","phone_lst.x","phone_lst.y","cids_adj_V1","cids_adj_V2","cids_adj_V1_old","cids_adj_V2_old"))]
write.table(fact_short, "pr_data/factors.csv", sep=",")
View(fact_short)
write.table(y_train, "pr_data/y_train.csv", sep=",")
fact_short <- all_factors [,!(colnames(all_factors) %in% c("cids_V1","cids_V2","phone_lst.x","phone_lst.y","cids_adj_V1","cids_adj_V2","cids_adj_V1_old","cids_adj_V2_old"))]
write.table(fact_short, "pr_data/factors.csv", sep=",")
plot_all_y_train (not_matched, data, img_path="non_matched")
all_factors <- read.table("pr_data/factors.csv", sep=",")
y_train <- read.table("pr_data/y_train.csv", sep=",")
y_train$class <- as.factor(y_train$class)
clf <- randomForest(all_factors,y_train$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, all_factors, type="response")
require(randomForest)
require(carret)
require(caret)
y_train$class <- as.factor(y_train$class)
clf <- randomForest(all_factors,y_train$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, all_factors, type="response")
confusionMatrix(testPred, testing$Class)
confusionMatrix(y_pred, y_train$class )
require(e1071)
if (!require(e1071)) install.packages('e1071')
if (!require(caret)) install.packages('caret')
