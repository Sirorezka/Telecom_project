clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
install.packages("pROC")
library(pROC)
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'auc'] = rocValues$auc
install.packages("pROC")
i <- 1
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
i <- 1
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'auc'] = rocValues$auc
}
n_folds_auc
# reading factors and train set
all_factors <- read.table("pr_data/factors.csv", sep=",")
y_train <- read.table("pr_data/y_train.csv", sep=",")
y_train$class <- as.factor(y_train$class)
# designing cross validation
n_folds <- createFolds(y_train$class, k = 5, list = FALSE)
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
}
n_folds_auc
cf_mat
cf_mat$byClass
cf_mat$byClass[]
cf_mat$byClass[1]
test_y$class
y_pred
precision <- sum((y_pred==1) & (true==1)) / sum((y_pred==1) )
precision <- sum((y_pred==1) & (test_y$class==1)) / sum((y_pred==1) )
precision
recall <- sum((y_pred==1) & (test_y$class==1)) / sum((test_y$class==1) )
recall
precision <- sum((y_pred==1) & (test_y$class==1)) / sum((y_pred==1) )
recall <- sum((y_pred==1) & (test_y$class==1)) / sum((test_y$class==1) )
f1 <- 2 * precision * recall / sum(precision +recall)
f1
f1_measure <- function (y_pred, y_real){
precision <- sum((y_pred==1) & (y_real==1)) / sum((y_pred==1) )
recall <- sum((y_pred==1) & (y_real==1)) / sum((y_real==1) )
f1 <- 2 * precision * recall / sum(precision +recall)
f1
}
f1_measure (y_pred, test_y$class)
# reading factors and train set
all_factors <- read.table("pr_data/factors.csv", sep=",")
y_train <- read.table("pr_data/y_train.csv", sep=",")
y_train$class <- as.factor(y_train$class)
# designing cross validation
n_folds <- createFolds(y_train$class, k = 5, list = FALSE)
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
n_folds_auc
# reading factors and train set
all_factors <- read.table("pr_data/factors.csv", sep=",")
y_train <- read.table("pr_data/y_train.csv", sep=",")
y_train$class <- as.factor(y_train$class)
# designing cross validation
n_folds <- createFolds(y_train$class, k = 5, list = FALSE)
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
n_folds_auc
range(1,20)
range(1,20,1)
range(5,20,1)
seq(5,20,1)
seq(50,300,10)
grid <- expand.grid(par_ntree = seq(50,300,10), par_maxnodes = seq(5,20,1))
grid
overall_score <- data.frame(NULL)
params <- grid[1]
params
params <- grid[1,1]
View(grid)
params <- grid[1,]
params
for (params in grid){
print (params)
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=150,maxnodes=20)
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
}
param_grid <- expand.grid(par_ntree = seq(50,300,10), par_maxnodes = seq(5,20,1))
g <- 1
params <-param_grid[g,]
params
params[1]
params[2]
for (i in unique(n_folds)){
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[1],maxnodes=params[2])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
n_folds_auc <- data.frame(NULL)
params <-param_grid[g,]
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
print (i)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[1],maxnodes=params[2])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
unique(n_folds)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[1],maxnodes=params[2])
params[1]
clf <- randomForest(train_X,train_y$class,ntree=params[[1]],maxnodes=params[[2]])
g <- 1
params <-param_grid[g,]
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
print (i)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[[1]],maxnodes=params[[2]])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
rocValues
n_folds_auc
auc_mean = mean(n_folds_auc$auc)
auc_mean
auc_mean = mean(n_folds_auc$auc)
f1_mean = mean(n_folds_auc$f1)
f1_min = min(n_folds_auc$f1)
f1_min
f1_mean
d_row = c(params,auc_mean,f1_mean,f1_min)
d_row
d_row = c(params[[1]],params[[2]],auc_mean,f1_mean,f1_min)
d_row
overall_score <- rbind(overall_score,d_row)
overall_score
names(overall_score) <- c("df","df")
overall_score <- data.frame(NULL)
names(overall_score) <- c("df","df")
overall_score
# 2. making grid search
param_grid <- expand.grid(par_ntree = seq(50,300,10), par_maxnodes = seq(5,20,1))
overall_score <- data.frame(NULL)
names(overall_score) <- c("df","df")
for (g in 1:nrow(param_grid)){
g <- 1
params <-param_grid[g,]
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
print (i)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[[1]],maxnodes=params[[2]])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
auc_mean = mean(n_folds_auc$auc)
f1_mean = mean(n_folds_auc$f1)
f1_min = min(n_folds_auc$f1)
d_row = c(params[[1]],params[[2]],auc_mean,f1_mean,f1_min)
overall_score <- rbind(overall_score,d_row)
}
overall_score
names (overall_score) <- c('p1','p2','auc_mean','f1_mean','f1_min')
overall_score
# 2. making grid search
param_grid <- expand.grid(par_ntree = seq(50,300,10), par_maxnodes = seq(5,20,1))
overall_score <- data.frame(NULL)
names(overall_score) <- c("df","df")
for (g in 1:nrow(param_grid)){
params <-param_grid[g,]
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
#print (i)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[[1]],maxnodes=params[[2]])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
auc_mean = mean(n_folds_auc$auc)
f1_mean = mean(n_folds_auc$f1)
f1_min = min(n_folds_auc$f1)
d_row = c(params[[1]],params[[2]],auc_mean,f1_mean,f1_min)
overall_score <- rbind(overall_score,d_row)
}
print (paste0("% completed: ",g/nrow(param_grid)))
overall_score
for (g in 1:nrow(param_grid)){
if (g %% 10 == 0) print (paste0("% completed: ",g/nrow(param_grid)*100))
params <-param_grid[g,]
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
#print (i)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[[1]],maxnodes=params[[2]])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
auc_mean = mean(n_folds_auc$auc)
f1_mean = mean(n_folds_auc$f1)
f1_min = min(n_folds_auc$f1)
d_row = c(params[[1]],params[[2]],auc_mean,f1_mean,f1_min)
overall_score <- rbind(overall_score,d_row)
}
# 2. making grid search
param_grid <- expand.grid(par_ntree = seq(50,300,10), par_maxnodes = seq(5,20,1))
overall_score <- data.frame(NULL)
names(overall_score) <- c("df","df")
for (g in 1:nrow(param_grid)){
if (g %% 10 == 0) print (paste0("% completed: ",round(g/nrow(param_grid)*100,2)))
params <-param_grid[g,]
n_folds_auc <- data.frame(NULL)
for (i in unique(n_folds)){
#print (i)
train_X <- all_factors[!(n_folds==i), 3:ncol(all_factors)]
test_X <- all_factors[n_folds==i, 3:ncol(all_factors)]
train_y <- y_train[!(n_folds==i),]
test_y <- y_train[(n_folds==i),]
clf <- randomForest(train_X,train_y$class,ntree=params[[1]],maxnodes=params[[2]])
round(importance(clf), 2)
y_pred <- predict(clf, test_X, type="response")
cf_mat <- confusionMatrix(y_pred, test_y$class )
cf_mat$byClass[]
rocValues <- roc(y_pred, as.numeric.factor(test_y$class))
n_folds_auc[i,'fold'] = i
n_folds_auc[i,'auc'] = rocValues$auc
n_folds_auc[i,'f1'] = f1_measure (y_pred, test_y$class)
}
auc_mean = mean(n_folds_auc$auc)
f1_mean = mean(n_folds_auc$f1)
f1_min = min(n_folds_auc$f1)
d_row = c(params[[1]],params[[2]],auc_mean,f1_mean,f1_min)
overall_score <- rbind(overall_score,d_row)
}
overall_score
View(all_factors)
data_fact <- read.xlsx ("data/01_facts.xlsx", sheetIndex=1, header= FALSE)
data <- read.csv2 ("data/02_Data_test.csv", header= TRUE)
View(data)
data
data [,('lac','cid')]
data [,c('lac','cid')]
unique(data [,c('lac','cid')])
nrow(unique(data [,c('lac','cid')]))
#Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_73')  # for 64 bit Java
if (!require (rJava)) install.packages ("rJava")
if (!require (xlsx)) install.packages ("xlsx")
if (!require (dplyr)) install.packages ("dplyr")
if (!require (tidyr)) install.packages ("tidyr")
if (!require (ggplot2)) install.packages ("ggplot2")
if (!require (gtools)) install.packages ("gtools")
if (!require (party)) install.packages ("party")
if (!require (rpart)) install.packages ("rpart")
if (!require (caret)) install.packages ("caret")
if (!require (geosphere)) install.packages ("geosphere")
if (!require (doParallel)) install.packages ("doParallel")
if (!require (foreach)) install.packages ("foreach")
if (!require(randomForest)) install.packages('randomForest')
if (!require(e1071)) install.packages('e1071')
if (!require(caret)) install.packages('caret')
if (!require(caret)) install.packages('pROC')
require (xlsx)
require (dplyr)
require (tidyr)
require (ggplot2)
require (party)
require (rpart)
require (caret)
require (geosphere)
require (doParallel)
require (foreach)
require(randomForest)
require(caret)
library(pROC)
##
##  --- Setting working directory
##
MAKE_PLOTS = F
# mywd <- "C:/Users/Administrator/Desktop/Telecom_project"
# mywd <- "C:/Users/Johnny/Documents/GitHub/test_task"
mywd <- "C:/Users/Ivan.Petrov/Documents/GitHub/test_task"
setwd (mywd)
getwd()
source ('my_utils.R')
####
####  --- Reading data sets  ----
####
data_fact <- read.xlsx ("data/01_facts.xlsx", sheetIndex=1, header= FALSE)
data <- read.csv2 ("data/02_Data_test.csv", header= TRUE)
data_tac <- read.csv2 ("data/03_devices.csv", header= FALSE, quote = '"')
nrow(unique(data [,c('lac','cid')]))
####
####  --- Processing tac table  ----
####
tt <- gsub('"','',data_tac[,1], perl=TRUE)
col_names <- strsplit (tt[1],",",perl=TRUE)[[1]]
col_names[2:4] <- c("device_vendor","device_platform","device_type")
tt <- tt[2:length(tt)]
data_tac <- as.data.frame(tt) %>% separate("tt",into = col_names, sep = ",")
####
####  --- Processing fact table  ----
####
# Searching for duplicates in fact table
data_fact <- as.data.frame(data_fact)
c1 <- as.data.frame(data_fact[,1])
c2 <- as.data.frame(data_fact [,2])
c1[duplicated(bind_rows(c1,c2)),]
as.character(data_fact[data_fact[,1]==158528850493,2])
rm(c1,c2)
# switching elements where id in first column is greater than id in second
# and ordering elements
for (i in 1:nrow(data_fact)){
if (data_fact[i,1]>data_fact[i,2]){
k <- data_fact[i,2]
data_fact[i,2]  <- data_fact[i,1]
data_fact[i,1] <- k
}
}
data_fact <- data_fact[order(data_fact [,1]),]
#removing rows which aren't present in data table
del_rows <- data_fact$X1 %in% unique(data$msisdn)
data_fact <- data_fact[del_rows,]
del_rows <- data_fact$X2 %in% unique(data$msisdn)
data_fact <- data_fact[del_rows,]
####
####  --- Preprocessing data table ----
####
# changing time to minutes
sec <- data[,'tstamp']/1000
data[,'tstamp'] <- as.POSIXct(sec,origin = "1970-01-01",tz = "Europe/Moscow")
c1 <- round(data[,'tstamp'], units = c("mins"))
c1 <- as.data.frame(c1)
data[,'tstamp'] <- c1
all_msisdn <- unique(data[,'msisdn'])
all_msisdn <- all_msisdn[order(all_msisdn)]
# joining tac (phone type data, vendor info, platform)
data[,'tac'] <- substr(data[,'imei'],1,8)
data <- data %>% left_join (data_tac, by=("tac"))
data[is.na(data$device_type),"device_type"] = -1
data[is.na(data$device_platform),"device_platform"] = -1
data[is.na(data$device_vendor),"device_vendor"] = -1
# converting long, lat, start_angle, end_angle to numeric
data$long <- as.numeric.factor(data$long)
data$lat <- as.numeric.factor(data$lat)
data$start_angle <- as.numeric.factor(data$start_angle)
data$end_angle <- as.numeric.factor(data$end_angle)
# we need to check if cid is unique and can be used as key for base station:
tb_cid_check <- unique(data[,c('lac','cid')])
tb_cid_check <- tb_cid_check %>% group_by(cid) %>% summarize (mm=length(list(lac)))
if (max(tb_cid_check$mm) == 1) print ("All cids are unique")
####
####  --- Plotting paths ---
####
# plot all paths on one graph with imei codes. We are searching for data with matching imei codes
if (MAKE_PLOTS) plot_all_fact_data (data_fact, data)
####
####  --- Generating train set ---
####
# Generating all posible combinations of msidns
all_fact_ids <- c(data_fact[,1],data_fact[,2])
sort(all_fact_ids)
y_train <- generate_all_combin (all_fact_ids)
# 'class' column will contain information if two msidn's match
y_train[,"class"] <- 0
# two msidn's match if they are present in fact_data
aa <- paste0(y_train[,"V1"],"_",y_train[,"V2"], collapse = NULL)
bb <- paste0(data_fact[,1],"_",data_fact[,2], collapse = NULL)
class1 <- aa %in% bb
y_train[class1,"class"] <- 1
# Sampling training data:
#
# - We need to take all pairs from class 1.
# - And for clazz 0 we will sample some points that not present in original data
y_train_1 <- y_train[y_train$class==1,]
y_train_0 <- y_train[y_train$class==0,]
y_train_0 <- y_train_0[sample(nrow(y_train_0),1100),]
y_train <- bind_rows(y_train_1,y_train_0)
rm(y_train_0,y_train_1)
if (MAKE_PLOTS) plot_all_y_train (y_train, data)
plot_all_y_train (y_train, data)
plot_all_y_train (y_train, data)
length(unique(data$msisdn))
View(all_factors)
